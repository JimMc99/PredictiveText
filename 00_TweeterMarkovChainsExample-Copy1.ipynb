{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chains for  D.Trump Tweets prediction\n",
    "\n",
    "This example shows how to feed Markov Chains with Tweets of D.Trump. The result will provide a sentence prediction of what is said in social media about him. \n",
    "\n",
    "## 0. - Running the example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1 - Load the module Tweeter\n",
    "from tweeter import Tweeter\n",
    "\n",
    "# 0.2 - Load the source to feed the Markov Chains algorithm\n",
    "trump_tweeter = Tweeter('trump_tweets.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"@Amber_Sadler22: Donald gets it!'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.3 - See the results of the prediction\n",
    "trump_tweeter.new_tweet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the results show one of the most comon users tweets about Trump.\n",
    "Download or clone this repository and run it again to get any other result! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. - In deeper with the code\n",
    "\n",
    "Tweeter module deciphered, to see how the content of this module is working, step by step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading Required libraries for the module Tweeter\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function 1\n",
    "\n",
    "def list_lines(fpath):\n",
    "    \"\"\"\n",
    "    Converts a text file to a list split by lines.\n",
    "    :param fpath: filepath of text file\n",
    "    :return: list of lines of text file\n",
    "    \"\"\"\n",
    "    with open(fpath, 'r', encoding='utf-8-sig') as f:\n",
    "        return f.readlines()\n",
    "\n",
    "# Class 1\n",
    "\n",
    "class Tweeter:\n",
    "    \n",
    "    def __init__(self, fpath):\n",
    "        self.fpath = fpath\n",
    "\n",
    "        self.markov_model_fo = defaultdict(lambda: Counter())\n",
    "        self.start_words = Counter()\n",
    "        self.__load_model()\n",
    "\n",
    "    def __load_model(self):\n",
    "        # load model (prepare data)\n",
    "        # first-order markov model of words (no preprocessing)\n",
    "        # each token key goes to a Counter value containing counts of the subsequent word\n",
    "        # to add to this model, markov_model_fo[current_word][next_word] += 1\n",
    "        tweets = list_lines(self.fpath)\n",
    "\n",
    "        for tweet in tweets:\n",
    "            tokens = tweet.split()\n",
    "\n",
    "            # add each token except the last token in the tweet to the markov model\n",
    "            for i, token in enumerate(tokens[:-1]):\n",
    "                self.markov_model_fo[token][tokens[i + 1]] += 1\n",
    "            # for the last token, nothing follows\n",
    "            if len(tokens):\n",
    "                self.markov_model_fo[tokens[-1]][None] += 1\n",
    "                self.start_words[tokens[0]] += 1\n",
    "\n",
    "    def new_tweet(self):\n",
    "        # create new tweet from model\n",
    "        new_tweet_list = []\n",
    "\n",
    "        start_keys = list(self.start_words.keys())\n",
    "        start_values = list(self.start_words.values())\n",
    "        start_word = random.choices(start_keys, weights=start_values)[0]\n",
    "\n",
    "        current_word = start_word\n",
    "\n",
    "        while current_word is not None:\n",
    "            new_tweet_list.append(current_word)\n",
    "\n",
    "            next_keys = list(self.markov_model_fo[current_word].keys())\n",
    "            next_values = list(self.markov_model_fo[current_word].values())\n",
    "            next_word = random.choices(next_keys, weights=next_values)[0]\n",
    "\n",
    "            current_word = next_word\n",
    "\n",
    "        return ' '.join(new_tweet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"@DannyBo4455: @hamishjoy Mr Trump? The Mayor in U.S. strongly in to everyone out all over the so many other alternatives.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1.1 Loading source into Tweeter class\n",
    "trump_tweeter = Tweeter('trump_tweets.txt')\n",
    "\n",
    "# 1.2 Load object of class Twitter into function new_tweet, and see the results! \n",
    "print(trump_tweeter.new_tweet())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The results does not need to make sense at all. This is just an experiment to show up how Markov chains model can be used to make sentence predictions by training them with tweets on one topic (in this case Donald trump)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
